## Overview : 

I'm excited to share that I've recently completed a web scraping project leveraging Scrapy, Python's robust web scraping library.

In this project, I created a reliable web scraping spider which extracts useful data across multiple interconnected webpages from a book catalogue website. I was able to manage requests, perform data extraction jobs, process, map and store stream of data with ease using Scrapy.


## Key Points:

- **Dynamic Data Extraction:** To traverse and retrieve structured data from different web pages, I implemented simple yet effective spider that utilizes pipeline and middleware components in Scrapy.
  
- **Data Storage:** To make it easier to analyze, share, and read from I stored scraped data in organized formats like CSV and JSON. I also learned how scraped data can be directly stored into connected databases and cloud storage.
  
- **Performance Optimization:** Implemented Scrapy's asynchronous capabilities and request handling to speed up scraping process efficiently.


## Socials
_LinkedIn_ : https://www.linkedin.com/in/y304/
